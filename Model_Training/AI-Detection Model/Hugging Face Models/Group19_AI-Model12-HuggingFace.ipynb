{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c44b5c-fa9e-4ec0-8b00-47d357daf7fb",
   "metadata": {},
   "source": [
    "### GROUP 19 - AI-Detection Content Modeling Phase (Hugging Face Models)\n",
    "NOTE: I did my own pre-processing steps and tested two Hugging Face models using the \"transformers\" library here (OpenAI and ChatGPT Roberta Models). The processed datasets with Classificaton and Confidence Scores took more than an hour to classify but the results are better compared to the custom model when it comes to Reddit Post contents. I highly recommend using this instead and its also easier for backend integration -- Dee\n",
    "\n",
    "Source AI-Human Dataset: https://www.kaggle.com/datasets/shanegerami/ai-vs-human-text\n",
    "\n",
    "Source Reddit Dataset: https://www.kaggle.com/datasets/cosmos98/twitter-and-reddit-sentimental-analysis-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5cfb21-0caf-4422-924b-1eb0d10d1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6a93b8-b2a9-44c9-9216-4fbe3b82ffcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       clean_comment  category\n",
      "0   family mormon have never tried explain them t...         1\n",
      "1  buddhism has very much lot compatible with chr...         1\n",
      "2  seriously don say thing first all they won get...        -1\n",
      "3  what you have learned yours and only yours wha...         0\n",
      "4  for your own benefit you may want read living ...         1\n"
     ]
    }
   ],
   "source": [
    "# Load the Reddit dataset\n",
    "reddit_data = pd.read_csv(\"Reddit_Data.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(reddit_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0de4cbf-9431-43dd-a8ba-d8cdf614f8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0   family mormon have never tried explain them t...\n",
      "1  buddhism has very much lot compatible with chr...\n",
      "2  seriously don say thing first all they won get...\n",
      "3  what you have learned yours and only yours wha...\n",
      "4  for your own benefit you may want read living ...\n"
     ]
    }
   ],
   "source": [
    "# Rename 'clean_comment' column to 'text' (if it exists)\n",
    "reddit_data = reddit_data.rename(columns={\"clean_comment\": \"text\"})\n",
    "\n",
    "# Drop the 'generated' column (removes sentiment classification)\n",
    "reddit_data = reddit_data.drop(columns=['category'], errors='ignore')\n",
    "\n",
    "# Display the first few rows\n",
    "print(reddit_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14a4684-9a02-4681-bac2-ccde145f63eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the 'text' column\n",
    "print(reddit_data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d332a256-1d73-4b5c-b2fd-979c115a0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the 'text' column\n",
    "reddit_data = reddit_data.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "314cdff1-c751-4f3d-9b49-5facec188733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values again\n",
    "print(reddit_data['text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83da44cb-1add-414b-8eb4-5c1d612f3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove special characters & numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "reddit_data['text'] = reddit_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e8e83f9-a08e-41cc-9425-91947831e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  family mormon have never tried explain them th...\n",
      "1  buddhism has very much lot compatible with chr...\n",
      "2  seriously don say thing first all they won get...\n",
      "3  what you have learned yours and only yours wha...\n",
      "4  for your own benefit you may want read living ...\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(reddit_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f7abd-ef29-499d-8945-17ee7a8d0d1e",
   "metadata": {},
   "source": [
    "### Hugging Face Dataset Labeling (Cleaned and Labeled Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40486427-c589-469f-baae-618c665798c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base-openai-detector were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load AI Text Detector from Hugging Face\n",
    "ai_detector = pipeline(\"text-classification\", model=\"roberta-base-openai-detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8295e2fe-5823-413a-8b9b-ead5fb38b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify text as human (0.0) or AI-generated (1.0)\n",
    "def classify_text(text):\n",
    "    result = ai_detector(text[:512])[0]  # Truncate long text to 512 tokens\n",
    "    return 1.0 if result['label'] == 'AI-Generated' else 0.0\n",
    "\n",
    "# Apply classification\n",
    "reddit_data['classification'] = reddit_data['text'].apply(classify_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0064a182-d35f-4cf6-ab83-c11707ceb46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  classification\n",
      "0  family mormon have never tried explain them th...             0.0\n",
      "1  buddhism has very much lot compatible with chr...             0.0\n",
      "2  seriously don say thing first all they won get...             0.0\n",
      "3  what you have learned yours and only yours wha...             0.0\n",
      "4  for your own benefit you may want read living ...             0.0\n",
      "5  you should all sit down together and watch the...             0.0\n",
      "6  was teens when discovered zen meditation was t...             0.0\n",
      "7                            jesus was zen meets jew             0.0\n",
      "8  there are two varieties christians dogmatic th...             0.0\n",
      "9  dont worry about trying explain yourself just ...             0.0\n"
     ]
    }
   ],
   "source": [
    "# Display first 10 rows to verify changes\n",
    "print(reddit_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bedfce2b-5dac-4971-b105-0449b6245374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "reddit_data.to_csv(\"Reddit_Cleaned_Classified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a47ed5-e1e2-45e1-b614-4f4506743272",
   "metadata": {},
   "source": [
    "### ACCURACY TEST (Based on Confidence Scores - Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6a1e8a-2120-4c28-a7ed-551261e96769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify text and return confidence score\n",
    "def classify_text_with_confidence(text):\n",
    "    result = ai_detector(text[:512])[0]  # Truncate long text to 512 tokens\n",
    "    label = 1.0 if result['label'] == 'AI-Generated' else 0.0\n",
    "    confidence = result['score']  # Confidence score\n",
    "    return label, confidence\n",
    "\n",
    "# Apply classification with confidence scores\n",
    "reddit_data[['classification', 'confidence']] = reddit_data['text'].apply(\n",
    "    lambda x: pd.Series(classify_text_with_confidence(x))\n",
    ")\n",
    "\n",
    "# Display the first 10 rows with confidence scores\n",
    "print(reddit_data[['text', 'classification', 'confidence']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf9a2e-fa40-40f4-9fa7-affaf8e7761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "reddit_data.to_csv(\"Reddit_Cleaned_Classified-ConfidenceScores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba597b6-33e6-4f44-90a6-95fe5e1b8efc",
   "metadata": {},
   "source": [
    "### Alternative Pre-trained Model to use for Classification (Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952d79e1-d513-40e3-b43e-98161f3524b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_detector = pipeline(\"text-classification\", model=\"Hello-SimpleAI/chatgpt-detector-roberta\")\n",
    "\n",
    "def alt_classify_text(text):\n",
    "    result = alt_detector(text[:512])[0]\n",
    "    return 1.0 if result['label'] == 'AI' else 0.0\n",
    "\n",
    "# Compare results\n",
    "reddit_data['alt_classification'] = reddit_data['text'].apply(alt_classify_text)\n",
    "\n",
    "# Display differences\n",
    "print(reddit_data[['text', 'classification', 'alt_classification']].sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82c49f-db7e-45fa-b1b7-9f7d5fce1206",
   "metadata": {},
   "source": [
    "### Updating the Code to Compute AI-Generated Percentage (Code Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c1924-b495-4a29-99c8-60d35ff8039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify text and return AI-Generated Percentage\n",
    "def classify_text_with_percentage(text):\n",
    "    result = ai_detector(text[:512])[0]  # Get classification result\n",
    "    ai_generated_percentage = result['score'] if result['label'] == 'AI-Generated' else (1 - result['score'])\n",
    "    return ai_generated_percentage * 100  # Convert to percentage\n",
    "\n",
    "# Apply classification with AI-Generated Percentage\n",
    "reddit_data['AI_Generated_Percentage'] = reddit_data['text'].apply(classify_text_with_percentage)\n",
    "\n",
    "# Display first 10 rows\n",
    "print(reddit_data[['text', 'AI_Generated_Percentage']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
